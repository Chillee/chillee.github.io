<!DOCTYPE html>
<html>
<link rel="stylesheet" type="text/css" href="index.css">
<head>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Horace He</title>
    <style type="text/css">
    img {
      width: 250px;
      padding-right: 10px;
    }
    li.research_item {
      width: 100%;
    }
    </style>

</head>

<nav class="menu">
    <ul class="menu__list">
      <li class="menu__group"><a href="index.html" class="menu__link">Horace He</a></li>
      <li class="menu__group"><a href="research.html" class="menu__link select__link">Research</a></li>
      <li class="menu__group"><a href="writing.html" class="menu__link">Writing</a></li>
      <li class="menu__group"><a href="projects.html" class="menu__link">Code</a></li>
      <li class="menu__group"><a href="cp.html" class="menu__link">Competition</a></li>
    </ul>
  </nav>


<body>
    <h1>Research</h1>
    <ul>
    <li class="research_item">
      <div class="container grid-item">
        <img src="img/simple.png" width="200px" style="float:left">
      </div>
      <b>Value Function Based Performance Optimization of Deep Learning Workloads</b>
      <br>
      Benoit Steiner, Chris Cummins, <b>Horace He</b>, Hugh Leather
      <br>
      <a href="http://mlforsystems.org/">NeurIPS Workshop on ML for Systems</a>
      <br>
      <a href="https://mlsys.org/">MLSys 2021</a>
      <br>
      [<a href="https://arxiv.org/abs/2011.14486">Paper</a>]
      <br>
      <b>TL;DR</b>: For the task of automatically optimizing deep learning workloads (e.g: matrix multiplies), we demonstrate that it's possible to utilize reinforcement learning to generate deep learning kernels much faster than previous methods that relied upon greedy cost models and autotuning. We outperform Halide/AutoTVM while generating schedules >100x faster.
    </li>
    <hr>
    <li class="research_item">
      <div class="container grid-item">
        <img src="img/simple.png" width="200px" style="float:left">
      </div>
      <b>Combining Label Propagation and Simple Models Out-performs Graph Neural Networks</b>
      <br>
      <b>Horace He*</b>, Qian Huang*, Abhay Singh, Ser-Nam Lim, Austin Benson
      <br>
      Under Review
      <br>
      [<a href="https://arxiv.org/abs/2010.13993">Paper</a>]
      <br>
      <b>TL;DR</b>: We demonstrate that for many popular transductive node classification tasks, state-of-the-art GNN models can be out-performed by a shallow MLP prediction followed by the post-processing of two Label Propagation variants. This simple framework directly uses label information and on some benchmarks, can outperform SOTA GNNs with orders of magnitude less parameters and runtime. Highlight result: We outperform SOTA GNNs on ogbn-products with 137x less parameters and >100x less runtime.
    </li>
    <hr>
    <li class="research_item">
      <div class="container grid-item">
        <img src="img/gator.png" width="200px" style="float:left">
      </div>
      <b>Geometry Types for Graphics Programming</b>
      <br>
      Dietrich Geisler, Irene Yoon, Aditi Kabra, <b>Horace He</b>, Yinnon Sanders, Adrian Sampson
      <br>
      <a href="https://2020.splashcon.org/track/splash-2020-oopsla">OOPSLA 2020</a>
      <br>
      [<a href="https://www.cs.cornell.edu/~asampson/media/papers/gator-oopsla2020-preprint.pdf">Paper</a>] [<a href="https://twitter.com/samps/status/1315690803130519552">Twitter Thread</a>]
      <br>
      <b>TL;DR</b>: Incorrect usage of coordinate systems (such as adding a vector in model space to a vector in world space) is responsible for a class of geometry bugs. Even worse, these bugs tend to be extremely nasty - often, it's not obvious if you've even had a bug. Gator marks geometric objects with their coordinate system and reference frame. Not only does this prevent the class of bugs mentioned above, it also allows for automatic generation of transformation code from one space to another.
    </li>
    <hr>
    <li class="research_item">
      <div class="container grid-item">
        <img src="img/BSR.jpg" width="200px" style="float:left">
      </div>
      <b>Better Set Representations for Relational Reasoning</b>
      <br>
      <b>Horace He*</b>, Qian Huang*, Abhay Singh, Yan Zhang, Ser-Nam Lim, Austin Benson
      <br>
      <a href="https://nips.cc/">NeurIPS 2020</a>
      <br>
      <a href="https://oolworkshop.github.io/">ICML 2020: Object-Oriented Learning Workshop</a>
      <br>
      [<a href="https://arxiv.org/abs/2003.04448">Paper</a>] [<a href="https://www.youtube.com/watch?v=Yhe5mZ-i6-Y">OOL Talk</a>]
      <br>
      <b>TL;DR</b>: Most methods for relational reasoning, like graph neural networks or transformers, need to operate on some kind of unordered set. However, the input(often an image) is not. Existing methods ignore the set structure. We show that by generating sets "properly", we can improve performance and robustness on a wide variety of tasks.
    </li>
    <hr>
    <li class="research_item">
      <div class="container grid-item">
        <img src="img/ILA.jpg" width="200px" style="float:left">
      </div>
      <b> Enhancing Adversarial Example Transferability with an Intermediate Level Attack </b>
      <br>
      <b>Horace He*</b>, Qian Huang*, Isay Katsman*, Zeqi Gu*, Serge Belongie, Ser-Nam Lim
      <br>
      <a href="http://iccv2019.thecvf.com/">ICCV 2019</a>
      <br>
      [<a href="https://arxiv.org/abs/1907.10823">Paper</a>] [<a href="https://slideslive.com/38922555/contributed-talk-5-enhancing-adversarial-example-transferability-with-an-intermediate-level-attack">Talk at WIML Workshop</a>] [<a href="https://twitter.com/cHHillee/status/1201705688898113536">Twitter Thread</a>] [<a href="https://news.cornell.edu/stories/2019/11/cs-undergrads-research-sets-sights-image-hackers">Cornell Chronicle</a>]
      <br>
      <b>TL;DR</b>: By optimizing the orthogonal projection of our perturbation onto an existing perturbation in the feature space, we can improve transferability significantly. Choosing the layer at which we optimize the projection changes the transferability significantly. Pretty surprising that this works.
      <br>
      <b>Open Question</b>: Why does this method work? We provide some guesses in the paper, but optimizing for the orthogonal projection obviously isn't fundamentally the <i>right</i> thing to do. After all, recursively applying our method to the perturbations doesn't generate better perturbations.
    </li>
    <hr>

    <li class="research_item">
      <div class="container grid-item">
        <img src="img/decomposition.jpg" width="200px" style="float:left">
      </div>
      <b> Adversarial Example Decomposition </b>
      <br>
      <b>Horace He</b>, Aaron Lou*, Qingxuan Jiang*, Isay Katsman*, Serge Belongie, Ser-Nam Lim
      <br>
      <a href="https://icml2019workshop.github.io/">ICML Workshop on Security and Privacy of Machine Learning</a>
      <br>
      [<a href="https://arxiv.org/abs/1812.01198">Paper</a>]
      <br>
      <b>TL;DR</b>: If you take the vector projection from a transferable perturbation to a regular perturbation, you get an extremely <b>non</b>-transferable perturbation.
    </li>

    </ul>



</body>

</html>